{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chemical-cream",
   "metadata": {},
   "source": [
    "<h1><center>Classification II: tutorial</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-hearts",
   "metadata": {},
   "source": [
    "<h3>Importing packages</h3>\n",
    "\n",
    "You should have `numpy`, `pandas`, `matplotlib` and `seaborn` installed from the previous session.\n",
    "\n",
    "Today we'll use additional functions from `sklearn` and `xgboost`.\n",
    "\n",
    "E.g. install the latter as (or your preferred method):\n",
    "> conda install -c anaconda py-xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assisted-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as mx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression # for Lasso and Elastic Net logistic regression\n",
    "from sklearn.svm import SVC # for Support Vector Classification\n",
    "from sklearn.feature_selection import RFE # for feature selection in SVM\n",
    "from sklearn.ensemble import RandomForestClassifier # for Random Forests\n",
    "from sklearn.ensemble import GradientBoostingClassifier # for Gradient Boosted Trees\n",
    "from sklearn.manifold import MDS # for visualising proximity matrix\n",
    "from xgboost import XGBClassifier # for XGBoost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "massive-catholic",
   "metadata": {},
   "source": [
    "<h3>Setting parameters</h3>\n",
    "\n",
    "To make it different for everyone, you'll use different parameters for the different algorithms.\n",
    "\n",
    "For the random seed write your CID without leading zeroes, e.g. instead of 01234567 you write 1234567 below.\n",
    "\n",
    "Choose your test set size, number of random iterations/trees (depending on model) and your n top most important variables to print as well.\n",
    "Test set size is a fraction between 0 and 1, the training data will be the remainder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-rally",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomSeed = 709878 # add your CID here without leading zeroes\n",
    "\n",
    "testSize = 1/5 # feel free to change this anywhere between 0.05 and 0.5\n",
    "\n",
    "nIter = 42 # feel free to change this, but don't go overboard - still need to do the computation in a reasonable time...\n",
    "\n",
    "nImpVars = 20 # feel free to change this"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-lemon",
   "metadata": {},
   "source": [
    "<h3>Your assignments during the tutorial</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-tokyo",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.RandomState(seed=randomSeed)\n",
    "classIImethodsA = ['Lasso', 'Random Forest', 'SVM-RFE']\n",
    "classIImethodsA = np.random.choice(classIImethodsA, size=3, replace=False)\n",
    "print('First do',classIImethodsA[0])\n",
    "print('Then do',classIImethodsA[1])\n",
    "print('Followed by',classIImethodsA[2])\n",
    "print('\\n')\n",
    "classIImethodsB = ['Elastic Net', 'Gradient Boosted Decision Trees and XGBoost', 'Nonlinear SVM-RFE']\n",
    "classIImethodsB = np.random.choice(classIImethodsB, size=3, replace=False)\n",
    "print('Then, if there is time left, do',classIImethodsB[0])\n",
    "print('Followed by',classIImethodsB[1])\n",
    "print('Last do',classIImethodsB[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-davis",
   "metadata": {},
   "source": [
    "<h3>Importing data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "QMDP_data = pd.read_excel('QMDiab_metabolomics_Preprocessed.xlsx', sheet_name='plasma')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(QMDP_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = QMDP_data.iloc[0:, 1:323].to_numpy() # identified metabolites\n",
    "y = QMDP_data.iloc[0:, 506].to_numpy() # type-2 diabetes status\n",
    "Xlabs = np.array(list(QMDP_data.columns[1:323]))\n",
    "p = Xlabs.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-border",
   "metadata": {},
   "source": [
    "<h3>Function and class to save and calculate performance using confusion matrix as input</h3>\n",
    "\n",
    "We'll use this for all algorithms to have a standardised output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atlantic-breach",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelPerformance(confMat):\n",
    "    TN = confMat[0, 0]\n",
    "    TP = confMat[1, 1]\n",
    "    FP = confMat[0, 1]\n",
    "    FN = confMat[1, 0]\n",
    "    prec = TP / (TP + FP)\n",
    "    rec = TP / (TP + FN)\n",
    "    spec = TN / (TN + FP)\n",
    "    fpr = FP / (TN + FP)\n",
    "    f1 = 2 * (prec * rec) / (prec + rec)\n",
    "    acc = (TP + TN) / (TP + FP + TN + FN)\n",
    "    return (acc, prec, rec, spec, fpr, f1)\n",
    "def printPerformance(confMat):\n",
    "    acc, prec, rec, spec, fpr, f1 = modelPerformance(confMat)\n",
    "    print(\"Accuracy = \" \"%.4f\" % acc)\n",
    "    print(\"Precision = \" \"%.4f\" % prec)\n",
    "    print(\"Recall = \" \"%.4f\" % rec)\n",
    "    print(\"Specificity = \" \"%.4f\" % spec)\n",
    "    print(\"False positive rate = \" \"%.4f\" % fpr)\n",
    "    print(\"F1-score = \" \"%.4f\" % f1)\n",
    "    np.set_printoptions(precision=2)\n",
    "    print(\"Confusion matrix (%):\")\n",
    "    print(confMat/np.sum(confMat)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-graduate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Result:\n",
    "    def __init__(self, cmat, impVar):\n",
    "        self.cmat = cmat\n",
    "        self.acc, self.prec, self.rec, self.spec, self.fpr, self.f1 = modelPerformance(cmat)\n",
    "        self.impVar = impVar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suited-reconstruction",
   "metadata": {},
   "source": [
    "<h3>Choose your model and setup</h3>\n",
    "\n",
    "You will find mocks for running a single model below for each of the examples methods.\n",
    "\n",
    "E.g. for penalised logistic regression, SVM and XGBoost this is one model, for random forests this is one ensemble of `nIter` trees. If you want to run multiple permutations of a model, have a look at the example for ridge logistic regression and implement it for penalised logistic regression, SVM and/or XGBoost.\n",
    "\n",
    "<b> Have a look at the comments behind functions, some of these indicate you <i>may</i> want to optimise/change some (hyper)parameters. Use the <a href=\"https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\">online documentation</a> in</b> `sklearn` <b>for classification to see how to do this.</b> Specifically, look at [`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) and [`RandomizedSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html).\n",
    "\n",
    "[`GridSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) goes through all possible combinations of parameters, this can be very slow if you aim to evaluate a large set of possible parameters values.\n",
    "\n",
    "The [`RandomizedSearchCV()`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) function evaluates the same set of parameters but instead you input the number of iterations (```n_iter```) which indicates how many random (remember to set the ```random_state```!) combinations are being evaluated. The higher the ```n_iter``` the more combinations will be evaluated, but also the slower it gets. Use this to balance the computation time. Set ```n_iter``` as your input value of _nIter_.\n",
    "\n",
    "It is fine to use the default values in this session if you have not used these methods before, if you have used them before then implement the hyperparameter tuning with one of these two methods.\n",
    "\n",
    "<h3>Ridge logistic regression with multiple permutations of the data</h3>\n",
    "\n",
    "Could also use `LogisticRegressionCV` (instead of `LogisticRegression`) here, see the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\">documentation online</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "motivated-xerox",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmat = np.zeros((2, 2), dtype=int)\n",
    "Bmat = np.zeros((p,nIter))\n",
    "for k in range(0, nIter):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=(randomSeed+k))\n",
    "    mdl = LogisticRegression(penalty='l2',random_state=(randomSeed-k),solver='liblinear').fit(X_train, y_train) # not using the lbfgs solver due to a bug\n",
    "    y_test_hat = mdl.predict(X_test)\n",
    "    cmat += mx.confusion_matrix(y_test, y_test_hat)\n",
    "    Bmat[:,k] = mdl.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breeding-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-commission",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get important variables (e.g. order based on average weights)\n",
    "Baw = np.mean(Bmat, axis=1)\n",
    "idx = (-abs(Baw)).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-radio",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_RR = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "connected-humidity",
   "metadata": {},
   "source": [
    "<h3>Lasso logit regression</h3>\n",
    "\n",
    "Adapt this code to include multiple permutations of the model (or use one that already includes cross-validation, see the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\">documentation online</a>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welcome-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = LogisticRegression(penalty='l1',random_state=(randomSeed-1),solver='liblinear').fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables (non-zero coefficients)\n",
    "B = mdl.coef_[0]\n",
    "idx = (-abs(B)).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "progressive-mills",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_lasso = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lyric-marriage",
   "metadata": {},
   "source": [
    "<h3>Random Forest</h3>\n",
    "\n",
    "Adapt this code to change the parameters used to calculate the forest.\n",
    "\n",
    "E.g. is there a difference in performance of using gini impurity compared to using entropy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-premises",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proximityMatrix(mdl, X, normalize=True):      \n",
    "    endNode = mdl.apply(X)\n",
    "    nTrees = endNode.shape[1]\n",
    "    n = X.shape[0]\n",
    "    proxMat = np.zeros((n,n))\n",
    "    for k in range(0, nTrees):\n",
    "        a = endNode[:,k]\n",
    "        proxMat += 1*np.equal.outer(a, a)\n",
    "    if normalize:\n",
    "        proxMat = proxMat / nTrees\n",
    "    return proxMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-afghanistan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = RandomForestClassifier(n_estimators=nIter, criterion='gini', random_state=randomSeed)\n",
    "mdl = mdl.fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "curious-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "backed-porter",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = (y_test).argsort()\n",
    "xM = X_test[ind,]\n",
    "yM = y_test[ind]\n",
    "proxMat = proximityMatrix(mdl, xM, normalize=True)\n",
    "ax = plt.axes()\n",
    "ax = sns.heatmap(proxMat, vmin=0, vmax=1, ax = ax)\n",
    "ax.set_title('Heatmap of ordered proximity matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "humanitarian-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = MDS(n_components=2,dissimilarity='precomputed',metric=True)\n",
    "S = emb.fit_transform(1-proxMat)\n",
    "S = pd.DataFrame({\"MDS_1\":S[:,0], \"MDS_2\":S[:,1]})\n",
    "sns.scatterplot(data = S, x = 'MDS_1', y = 'MDS_2', hue = yM)\n",
    "plt.title('MDS visualisation of proximity matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables\n",
    "idx = (-(mdl.feature_importances_)).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_RF = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-demand",
   "metadata": {},
   "source": [
    "<h3>Linear Support Vector Classification</h3>\n",
    "\n",
    "Adapt this code to include multiple permutations of the model (or use one that already includes cross-validation).\n",
    "\n",
    "Next you can try to use another classifier (such as `NuSVM`), or to see <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.RFECV.html#sklearn.feature_selection.RFECV\">documentation online</a> for finding the optimal number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = SVC(kernel='linear',C=1) # is not optimising the cost...\n",
    "mdl.fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "federal-islam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables (beta weights)\n",
    "B = mdl.coef_[0]\n",
    "idx = (-abs(B)).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_linearSVM = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pleased-pendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform RFE on the data to find 10 most important variables\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "est = SVC(kernel='linear',C=1) # is not optimising the cost...\n",
    "mdl = RFE(est, n_features_to_select=nImpVars, step=.1) # does not do cross-validation to select the optimal number of features\n",
    "mdl.fit(X_train, y_train)\n",
    "# get important variables (from variable selection using RFE)\n",
    "idx = mdl.ranking_==1\n",
    "print(Xlabs[idx])\n",
    "mdl = SVC(kernel='linear',C=1) # is not optimising the cost...\n",
    "xtr = X_train[:,idx]\n",
    "xte = X_test[:,idx]\n",
    "mdl.fit(xtr, y_train)\n",
    "y_test_hat = mdl.predict(xte)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impressed-projection",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-transaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_linearSVMRFE = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confused-design",
   "metadata": {},
   "source": [
    "<h3>Support Vector Classification with non-linear kernel</h3>\n",
    "\n",
    "Choose a non-linear kernel (see documentation online).\n",
    "\n",
    "Adapt this code to include multiple permutations of the model (or use one that already includes cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divine-neutral",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = SVC(kernel='rbf',C=1,gamma='scale') # is not optimising the cost...\n",
    "mdl.fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ruled-relief",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "economic-psychiatry",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc, prec, rec, spec, fpr, f1 = modelPerformance(cmat) # calculate model values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-acoustic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables (remove 1 variable at a time and evaluate drop in performance as measure or importance)\n",
    "deltaAcc = np.zeros((1,p))\n",
    "for k in range(0,p):\n",
    "    mdlMinK = SVC(kernel='rbf',C=1,gamma='scale') # is not optimising the cost...\n",
    "    xtr = np.delete(X_train,k,1)\n",
    "    xte = np.delete(X_test,k,1)\n",
    "    mdlMinK.fit(xtr, y_train)\n",
    "    y_test_hat = mdlMinK.predict(xte)\n",
    "    cmatMinK = mx.confusion_matrix(y_test, y_test_hat)\n",
    "    accMinK, precMinK, recMinK, specMinK, fprMinK, f1MinK = modelPerformance(cmatMinK) # calculate model values\n",
    "    deltaAcc[0,k] = acc - accMinK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interim-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = (-deltaAcc[0]).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-verse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_nonlinearSVM = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "duplicate-designer",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = SVC(kernel='rbf',C=1,gamma='scale') # is not optimising the cost, or other hyperparameters...\n",
    "# we're taking the top 10 most important variables based on accuracy drop, but perhaps as with linear-RFE there is another optimum?\n",
    "# sklearn's RFE only works for linear kernels, hence the workaround above (but you should be to see how one could write it themselves)\n",
    "xtr = X_train[:,idx]\n",
    "xte = X_test[:,idx]\n",
    "mdl.fit(xtr, y_train)\n",
    "y_test_hat = mdl.predict(xte)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-desktop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "# it's technically not RFE what was done, since variable accuracy drop was defined relative to all other variables\n",
    "# it would have to be repeated multiple times in steps as with linear RFE (however would take a lot of time)\n",
    "# but after this session you could try and code it?\n",
    "result_nonlinearSVMRFE = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-spiritual",
   "metadata": {},
   "source": [
    "<h3>Gradient Boosted Decision Trees and XGBoost</h3>\n",
    "\n",
    "Set/optimize the hyperparameters (see documentation online for <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\">GBDT</a> and <a href=\"https://xgboost.readthedocs.io/en/latest/parameter.html\">XGB</a>).\n",
    "\n",
    "Adapt this code to include multiple permutations of the model (or use one that already includes cross-validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosted Trees\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = GradientBoostingClassifier(n_estimators=nIter, learning_rate=1.0, max_depth=1, random_state=(randomSeed-1))\n",
    "mdl.fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-vatican",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-ontario",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables\n",
    "idx = (-mdl.feature_importances_).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "racial-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_GBDT = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-science",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = XGBClassifier(subsample=2/3,objective='reg:logistic',seed=(randomSeed-1))\n",
    "mdl.fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-internship",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "simple-lancaster",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables\n",
    "idx = (-mdl.feature_importances_).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-cruise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_XGBoost = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-intelligence",
   "metadata": {},
   "source": [
    "<h3>Elastic Net logit regression</h3>\n",
    "\n",
    "Optimize the hyperparameters. Below it is only done for a single alpha value (`l1_ratio`), this is rarely optimal.\n",
    "E.g. use one that already includes cross-validation (see the <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\">documentation online</a>).\n",
    "\n",
    "Adapt this code to include multiple permutations of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "martial-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomSeed)\n",
    "mdl = LogisticRegression(penalty='elasticnet',random_state=(randomSeed-1),solver='saga',l1_ratio=0.5,max_iter=5000).fit(X_train, y_train)\n",
    "y_test_hat = mdl.predict(X_test)\n",
    "cmat = mx.confusion_matrix(y_test, y_test_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proud-collection",
   "metadata": {},
   "outputs": [],
   "source": [
    "printPerformance(cmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-kentucky",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get important variables (non-zero coefficients)\n",
    "B = mdl.coef_[0]\n",
    "idx = (-abs(B)).argsort()[:nImpVars]\n",
    "print(Xlabs[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results to use compare with later\n",
    "result_EN = Result(cmat,Xlabs[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-drove",
   "metadata": {},
   "source": [
    "<h3>Recap</h3>\n",
    "\n",
    "This tutorial was intended to give you <i>some</i> experience with these models and to compare the outcomes.\n",
    "\n",
    "However it does not mean that your best model here is always the best model to use for other data.\n",
    "\n",
    "With all of these models, there are many different parameters to choose from to change the outcome of the model.\n",
    "\n",
    "Have a look in the documentation for some of these and see if you can improve on your best model? Or try <a href=\"https://scikit-learn.org/stable/supervised_learning.html#supervised-learning\">other supervised models</a>.\n",
    "\n",
    "Best practice is to split the data in 3 ways: training, validation and text. Training is to build your models, validation is to pick the optimal hyperparameters, and test is used to give an unbiased estimate of the performance of the model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1-scores:')\n",
    "print(\"Ridge: \" \"%.4f\" % result_RR.f1)\n",
    "print(\"Lasso: \" \"%.4f\" % result_lasso.f1)\n",
    "print(\"Elastic Net: \" \"%.4f\" % result_EN.f1)\n",
    "print(\"linear SVM: \" \"%.4f\" % result_linearSVM.f1)\n",
    "print(\"linear SVM-RFE: \" \"%.4f\" % result_linearSVMRFE.f1)\n",
    "print(\"Non-linear SVM: \" \"%.4f\" % result_nonlinearSVM.f1)\n",
    "print(\"Non-linear SVM-RFE: \" \"%.4f\" % result_nonlinearSVMRFE.f1)\n",
    "print(\"Random Forest: \" \"%.4f\" % result_RF.f1)\n",
    "print(\"GBDT: \" \"%.4f\" % result_GBDT.f1)\n",
    "print(\"XGBoost: \" \"%.4f\" % result_XGBoost.f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-bubble",
   "metadata": {},
   "source": [
    "<h3>Do after this session: stratified analysis</h3>\n",
    "\n",
    "Do the analyses you did above for women and men separately, do the results change (predictive ability, important variables)?\n",
    "\n",
    "You can also look at associations of <u>individual</u> (important) variables to see if they are different based on sex e.g. using differences in regression coefficients as you did in <i>Introduction to Statistical Learning in Python</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "private-decade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
